{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input and output file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file=\"C:/Users/yrui7/Downloads/BillGates_2010.wav\"\n",
    "output_file_path = \"C:/Users/yrui7/Downloads/recognized_conversation_text.txt\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SessionStarted event\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yrui7\\Documents\\vscode\\conversation transcriber.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yrui7/Documents/vscode/conversation%20transcriber.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         time\u001b[39m.\u001b[39msleep(\u001b[39m.5\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yrui7/Documents/vscode/conversation%20transcriber.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     conversation_transcriber\u001b[39m.\u001b[39mstop_transcribing_async()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yrui7/Documents/vscode/conversation%20transcriber.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m recognize_from_file(input_file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yrui7/Documents/vscode/conversation%20transcriber.ipynb#W1sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(output_file_path, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m output_file:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yrui7/Documents/vscode/conversation%20transcriber.ipynb#W1sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     output_file\u001b[39m.\u001b[39mwrite(transcription_output)\n",
      "\u001b[1;32mc:\\Users\\yrui7\\Documents\\vscode\\conversation transcriber.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yrui7/Documents/vscode/conversation%20transcriber.ipynb#W1sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# Waits for completion.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yrui7/Documents/vscode/conversation%20transcriber.ipynb#W1sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m transcribing_stop:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yrui7/Documents/vscode/conversation%20transcriber.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m.5\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yrui7/Documents/vscode/conversation%20transcriber.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m conversation_transcriber\u001b[39m.\u001b[39mstop_transcribing_async()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "output_file_path = output_file_path\n",
    "transcription_output = \"\"\n",
    "\n",
    "\n",
    "def conversation_transcriber_recognition_canceled_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('Canceled event')\n",
    "\n",
    "def conversation_transcriber_session_stopped_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('SessionStopped event')\n",
    "\n",
    "def conversation_transcriber_transcribed_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "    global transcription_output\n",
    "    if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        #print('\\tSpeaker ID={}:'.format(evt.result.speaker_id))\n",
    "        #print('\\t{}'.format(evt.result.text))\n",
    "        transcription_output += f\"Speaker ID={evt.result.speaker_id}:\\n{evt.result.text}\\n\\n\"\n",
    "\n",
    "    elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        #print('\\tNOMATCH: Speech could not be TRANSCRIBED: {}'.format(evt.result.no_match_details))\n",
    "        transcription_output += f\"NOMATCH: Speech could not be TRANSCRIBED: {evt.result.no_match_details}\\n\\n\"\n",
    "\n",
    "def conversation_transcriber_session_started_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('SessionStarted event')\n",
    "    \n",
    "def recognize_from_file(input_file):\n",
    "    # This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=os.getenv('SPEECH_SERVICE_KEY'), region=os.getenv('SPEECH_REGION'))\n",
    "    speech_config.speech_recognition_language=\"en-US\"\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=input_file)\n",
    "    conversation_transcriber = speechsdk.transcription.ConversationTranscriber(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    transcribing_stop = False\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        #\"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal transcribing_stop\n",
    "        transcribing_stop = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the conversation transcriber\n",
    "    conversation_transcriber.transcribed.connect(conversation_transcriber_transcribed_cb)\n",
    "    conversation_transcriber.session_started.connect(conversation_transcriber_session_started_cb)\n",
    "    conversation_transcriber.session_stopped.connect(conversation_transcriber_session_stopped_cb)\n",
    "    conversation_transcriber.canceled.connect(conversation_transcriber_recognition_canceled_cb)\n",
    "    # stop transcribing on either session stopped or canceled events\n",
    "    conversation_transcriber.session_stopped.connect(stop_cb)\n",
    "    conversation_transcriber.canceled.connect(stop_cb)\n",
    "\n",
    "    conversation_transcriber.start_transcribing_async()\n",
    "\n",
    "    # Waits for completion.\n",
    "    while not transcribing_stop:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    conversation_transcriber.stop_transcribing_async()\n",
    "\n",
    "recognize_from_file(input_file)\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    output_file.write(transcription_output)\n",
    "\n",
    "print(\"Saved content:\\n\", transcription_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries abstracted:\n",
      "The speaker discusses the importance of energy and climate change, particularly for the world's poorest 2 billion people. They highlight the need to reduce the amount of CO2 emitted from energy production to zero, which will significantly impact the planet's natural ecosystems. The speaker suggests five potential energy solutions: fossil fuels, renewable sources, geothermal, fusion, and biofuels, each with their own challenges. They also mention the potential of nuclear energy, particularly the concept of Tarrant power, which could provide significant energy storage and waste disposal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "\n",
    "def sample_abstractive_summarization() -> None:\n",
    "    endpoint = os.getenv('AZURE_LANGUAGE_ENDPOINT')\n",
    "    key = os.getenv('AZURE_LANGUAGE_KEY')\n",
    "\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureKeyCredential(key),\n",
    "    )\n",
    "    # Replace this with the recognized text you want to summarize\n",
    "    #recognized_text = open_file(output_file)\n",
    "\n",
    "    document = [ {\"id\": \"1\", \"text\": transcription_output}]\n",
    "\n",
    "    poller = text_analytics_client.begin_abstract_summary(document)\n",
    "    abstract_summary_results = poller.result()\n",
    "    for result in abstract_summary_results:\n",
    "        if result.kind == \"AbstractiveSummarization\":\n",
    "            print(\"Summaries abstracted:\")\n",
    "            [print(f\"{summary.text}\\n\") for summary in result.summaries]\n",
    "        elif result.is_error is True:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                result.error.code, result.error.message\n",
    "            ))\n",
    "    # [END abstract_summary]\n",
    "    \n",
    "sample_abstractive_summarization()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
